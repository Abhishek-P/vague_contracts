{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/falseConsensus/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import GPT2TokenizerFast\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>nYes</th>\n",
       "      <th>nNo</th>\n",
       "      <th>nCantDecide</th>\n",
       "      <th>propYes</th>\n",
       "      <th>propNo</th>\n",
       "      <th>propCantDecide</th>\n",
       "      <th>item</th>\n",
       "      <th>header</th>\n",
       "      <th>continuation</th>\n",
       "      <th>completion_numeric</th>\n",
       "      <th>completion</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Damages I</td>\n",
       "      <td>controversial</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>Emergency Damages</td>\n",
       "      <td>Joanne's home insurance covers \"Emergency Dama...</td>\n",
       "      <td>Late one night, Joanne hears loud crashing noi...</td>\n",
       "      <td>70</td>\n",
       "      <td>seventy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emergency Damages I</td>\n",
       "      <td>unambiguous_covered</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Emergency Damages</td>\n",
       "      <td>Joanne's home insurance covers \"Emergency Dama...</td>\n",
       "      <td>Late one night, Joanne hears loud crashing noi...</td>\n",
       "      <td>100</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emergency Damages I</td>\n",
       "      <td>unambiguous_uncovered</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>Emergency Damages</td>\n",
       "      <td>Joanne's home insurance covers \"Emergency Dama...</td>\n",
       "      <td>Late one night, Joanne hears loud crashing noi...</td>\n",
       "      <td>40</td>\n",
       "      <td>forty</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emergency Damages II</td>\n",
       "      <td>controversial</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Emergency Damages</td>\n",
       "      <td>Salma's home insurance covers \"Emergency Damag...</td>\n",
       "      <td>Late one night, Salma hears noises coming from...</td>\n",
       "      <td>50</td>\n",
       "      <td>fifty</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergency Damages II</td>\n",
       "      <td>unambiguous_covered</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Emergency Damages</td>\n",
       "      <td>Salma's home insurance covers \"Emergency Damag...</td>\n",
       "      <td>Late one night, Salma hears noises coming from...</td>\n",
       "      <td>100</td>\n",
       "      <td>everyone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                version  nYes  nNo  nCantDecide  \\\n",
       "0   Emergency Damages I          controversial    24    7            4   \n",
       "1   Emergency Damages I    unambiguous_covered    22    0            0   \n",
       "2   Emergency Damages I  unambiguous_uncovered     8    9            2   \n",
       "3  Emergency Damages II          controversial    17   14            0   \n",
       "4  Emergency Damages II    unambiguous_covered    27    0            0   \n",
       "\n",
       "    propYes    propNo  propCantDecide               item  \\\n",
       "0  0.685714  0.200000        0.114286  Emergency Damages   \n",
       "1  1.000000  0.000000        0.000000  Emergency Damages   \n",
       "2  0.421053  0.473684        0.105263  Emergency Damages   \n",
       "3  0.548387  0.451613        0.000000  Emergency Damages   \n",
       "4  1.000000  0.000000        0.000000  Emergency Damages   \n",
       "\n",
       "                                              header  \\\n",
       "0  Joanne's home insurance covers \"Emergency Dama...   \n",
       "1  Joanne's home insurance covers \"Emergency Dama...   \n",
       "2  Joanne's home insurance covers \"Emergency Dama...   \n",
       "3  Salma's home insurance covers \"Emergency Damag...   \n",
       "4  Salma's home insurance covers \"Emergency Damag...   \n",
       "\n",
       "                                        continuation completion_numeric  \\\n",
       "0  Late one night, Joanne hears loud crashing noi...                 70   \n",
       "1  Late one night, Joanne hears loud crashing noi...                100   \n",
       "2  Late one night, Joanne hears loud crashing noi...                 40   \n",
       "3  Late one night, Salma hears noises coming from...                 50   \n",
       "4  Late one night, Salma hears noises coming from...                100   \n",
       "\n",
       "  completion  index  \n",
       "0    seventy      0  \n",
       "1   everyone      1  \n",
       "2      forty      2  \n",
       "3      fifty      3  \n",
       "4   everyone      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../results/1_falseconsensus/fineTuneDataSet.csv\")\n",
    "df[\"completion_numeric\"] = np.around(df[\"propYes\"],1) * 100\n",
    "df[\"completion_numeric\"] = df[\"completion_numeric\"].astype(int)\n",
    "df[\"completion_numeric\"] = df[\"completion_numeric\"].astype(str)\n",
    "df[\"completion\"] = df[\"completion_numeric\"].replace(['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100',], \n",
    "                                                    ['none','ten','twenty','thirty','forty','fifty','sixty','seventy','eighty','ninety','everyone'])\n",
    "df[\"index\"] = np.arange(len(df))\n",
    "df[\"item\"] = df[\"item\"].replace(\"Vehicle TheftVe\", \"Vehicle Theft\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'none': [4844], 'ten': [3478], 'twenty': [8208], 'thirty': [12277], 'forty': [16571], 'fifty': [15334], 'sixty': [24742], 'seventy': [31989], 'eighty': [37516], 'ninety': [37989], 'everyone': [2506]}\n"
     ]
    }
   ],
   "source": [
    "# FOR LOGIT BIAS, WHICH WILL RESTRICT OUTPUT TO INTEGERS ON THE RANGE OF [1,100]\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "labels = ['none','ten','twenty','thirty','forty','fifty','sixty','seventy','eighty','ninety','everyone']\n",
    "labels_tokens = {label: tokenizer.encode(\" \" + label) for label in labels}\n",
    "print(labels_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4844: 100, 3478: 100, 8208: 100, 12277: 100, 16571: 100, 15334: 100, 24742: 100, 31989: 100, 37516: 100, 37989: 100, 2506: 100}\n"
     ]
    }
   ],
   "source": [
    "tokens = [value[0] for key, value in labels_tokens.items()]\n",
    "logit_biases = {}\n",
    "for i in tokens:\n",
    "    logit_biases[i] = 100\n",
    "print(logit_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION THAT TAKES AS ITS INPUT DATAFRAME AND # OF DESIRED EXAMPLES FOR FEW-SHOT PROMPTING\n",
    "# OUTPUTS AN EVALUATION DATAFRAME THAT INCLUDES PROMPTS W/ RANDOMLY-SAMPLED DATA FROM DATAFRAME\n",
    "# (EVALUATION DATAFRAME EXCLUDES THOSE EXAMPLES)\n",
    "def create_evaluation_dataset(df, n_exampleGroups):\n",
    "    prompt_header = \"\"\n",
    "    exampleGroups = np.random.choice(np.unique(df[\"title\"]),n_exampleGroups)\n",
    "    examples = df[df[\"title\"].isin(exampleGroups)].index\n",
    "    for index in examples:\n",
    "        prompt_header += \"PROMPT: \" + df[\"header\"][index] + \" \" + df[\"continuation\"][index] + \"\\n\"\n",
    "        # prompt_header += \"Out of 100 randomly-sampled people, approximately how many would believe that the claim is covered under \" + df[\"item\"][index] + \" as it appears in the policy?\" + \"\\n\"\n",
    "        prompt_header += \"COMPLETION: Out of one hundred randomly-sampled English speakers, it is estimated that \" + df[\"completion\"][index] + \" would believe that the claim is covered under \" + df[\"item\"][index] + \" as it appears in the policy.\\n\\n---\\n\\n\"\n",
    "    eval_set = df[~(np.isin(df[\"index\"],examples))].copy(deep=False)\n",
    "    eval_set[\"prompt_noexample\"] = \"PROMPT: \" + eval_set[\"header\"] + \" \" + eval_set[\"continuation\"] + \"\\n\" + \"COMPLETION: Out of 100 randomly-sampled English speakers, it is estimated that \"\n",
    "    eval_set[\"prompt_withexamples\"] = prompt_header + eval_set[\"prompt_noexample\"]\n",
    "    eval_set[\"prompt_suffix\"] = \" would believe that the claim is covered under \" + eval_set[\"item\"] + \" as it appears in the policy.\"\n",
    "    return eval_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEvalSet = create_evaluation_dataset(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' would believe that the claim is covered under Wind Damage as it appears in the policy.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testEvalSet[\"prompt_suffix\"][137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fewAndZeroShot(df, n_exampleGroups, n_runs, seed_start, openai_model):\n",
    "    colnames = np.copy(df.columns)\n",
    "    colnames = np.insert(colnames, 0, \"random_seed\")\n",
    "    output =  pd.DataFrame(columns = colnames)\n",
    "    for i in range(0, n_runs):\n",
    "        print(\"Starting run \" + str(i + 1) + \" of \" + str(n_runs))\n",
    "        np.random.seed(seed_start+i+1)\n",
    "        evalSet = create_evaluation_dataset(df, n_exampleGroups)\n",
    "        evalSet[\"predictions_zeroshot\"] = evalSet.apply(lambda x : openai.Completion.create(model=openai_model, \n",
    "                                    prompt=x[\"prompt_noexample\"],   \n",
    "                                    logit_bias=logit_biases,  \n",
    "                                    suffix=x[\"prompt_suffix\"],                                                    \n",
    "                                    temperature=0, max_tokens=1).choices[0].text, axis = 1)\n",
    "        evalSet[\"predictions_fewshot\"] = evalSet.apply(lambda x : openai.Completion.create(model=openai_model, \n",
    "                                        prompt=x[\"prompt_withexamples\"],   \n",
    "                                        logit_bias=logit_biases,\n",
    "                                        suffix=x[\"prompt_suffix\"],\n",
    "                                        temperature=0, max_tokens=1).choices[0].text, axis = 1)\n",
    "        evalSet[\"random_seed\"] = seed_start+i+1\n",
    "        output = pd.concat([output, evalSet])\n",
    "    output['predictions_zeroshot_numeric'] = output[\"predictions_zeroshot\"].replace([' none',' ten',' twenty',' thirty',' forty',' fifty',' sixty',' seventy',' eighty',' ninety',' everyone'],\n",
    "                                                                                     ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'])\n",
    "    output['predictions_fewshot_numeric'] = output[\"predictions_fewshot\"].replace([' none',' ten',' twenty', ' thirty',' forty',' fifty',' sixty',' seventy',' eighty',' ninety',' everyone'],\n",
    "                                                                                     ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1 of 5\n",
      "Starting run 2 of 5\n",
      "Starting run 3 of 5\n",
      "Starting run 4 of 5\n",
      "Starting run 5 of 5\n"
     ]
    }
   ],
   "source": [
    "comparison_3ex_10runs_davinci_batch1 = compare_fewAndZeroShot(df, n_exampleGroups = 3, n_runs = 5, seed_start = 0, openai_model = \"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_3ex_10runs_davinci_batch1.to_csv(\"comparison_3ex_10runs_davinci_batch1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1 of 5\n",
      "Starting run 2 of 5\n",
      "Starting run 3 of 5\n",
      "Starting run 4 of 5\n",
      "Starting run 5 of 5\n"
     ]
    }
   ],
   "source": [
    "comparison_3ex_10runs_davinci_batch2 = compare_fewAndZeroShot(df, n_exampleGroups = 3, n_runs = 5, seed_start = 5, openai_model = \"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1 of 5\n",
      "Starting run 2 of 5\n",
      "Starting run 3 of 5\n",
      "Starting run 4 of 5\n",
      "Starting run 5 of 5\n"
     ]
    }
   ],
   "source": [
    "comparison_3ex_10runs_davinci_batch3 = compare_fewAndZeroShot(df, n_exampleGroups = 3, n_runs = 5, seed_start = 10, openai_model = \"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_3ex_10runs_davinci_batch2.to_csv(\"comparison_3ex_10runs_davinci_batch2.csv\")\n",
    "comparison_3ex_10runs_davinci_batch3.to_csv(\"comparison_3ex_10runs_davinci_batch3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falseConsensus",
   "language": "python",
   "name": "falseconsensus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
